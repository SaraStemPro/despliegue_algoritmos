{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 2: Generar .py de funciones y main con al menos dos argumentos de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting funciones.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile funciones.py\n",
        "import argparse\n",
        "import subprocess\n",
        "import time\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.datasets import load_wine\n",
        "from pyngrok import ngrok\n",
        "\n",
        "def argumentos():\n",
        "    parser = argparse.ArgumentParser(description='__main__ de la aplicación con argumentos de entrada.')\n",
        "    parser.add_argument('--nombre_job', type=str, help='Nombre del experimento en MLflow.')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def load_dataset():\n",
        "    wine = load_wine()\n",
        "    df = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n",
        "    df['target'] = wine['target']\n",
        "    return df\n",
        "\n",
        "def data_treatment(df):\n",
        "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    test_target = test['target']\n",
        "    test[['target']].to_csv('test-target.csv', index=False)\n",
        "    del test['target']\n",
        "    test.to_csv('test.csv', index=False)\n",
        "\n",
        "    features = [x for x in list(train.columns) if x != 'target']\n",
        "    x_raw = train[features]\n",
        "    y_raw = train['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x_raw, y_raw,\n",
        "                                                        test_size=0.20,\n",
        "                                                        random_state=123,\n",
        "                                                        stratify=y_raw)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def setup_ngrok(port=6000):\n",
        "    ngrok.set_auth_token('token_aqui') # indicar token\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(\"ngrok URL:\", public_url)\n",
        "    return public_url\n",
        "\n",
        "def mlflow_tracking(nombre_job, X_train, X_test, y_train, y_test, port=6000):\n",
        "    mlflow_ui_process = subprocess.Popen(['mlflow', 'ui', '--port', str(port)])\n",
        "    print(mlflow_ui_process)\n",
        "    time.sleep(5)\n",
        "    mlflow.set_experiment(nombre_job)\n",
        "\n",
        "    models_params = {\n",
        "        'LogisticRegression': (LogisticRegression(max_iter=1000), {\n",
        "            \"model__C\": [0.1, 1, 10],\n",
        "            \"model__solver\": [\"liblinear\", \"lbfgs\"]\n",
        "        }),\n",
        "        'KNeighborsClassifier': (KNeighborsClassifier(), {\n",
        "            \"model__n_neighbors\": [3, 5, 7],\n",
        "            \"model__weights\": [\"uniform\", \"distance\"]\n",
        "        })\n",
        "    }\n",
        "\n",
        "    for model_name, (model, params) in models_params.items():\n",
        "        with mlflow.start_run(run_name=model_name) as run:\n",
        "            preprocessor = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "            clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                  ('model', model)])\n",
        "            \n",
        "            grid_search = GridSearchCV(clf, params, cv=5, scoring='accuracy')\n",
        "            grid_search.fit(X_train, y_train)\n",
        "\n",
        "            best_params = grid_search.best_params_\n",
        "            accuracy_train = grid_search.score(X_train, y_train)\n",
        "            accuracy_test = grid_search.score(X_test, y_test)\n",
        "            y_pred = grid_search.predict(X_test)\n",
        "            report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "            mlflow.log_params(best_params)\n",
        "            mlflow.log_metric('accuracy_train', accuracy_train)\n",
        "            mlflow.log_metric('accuracy_test', accuracy_test)\n",
        "            mlflow.sklearn.log_model(grid_search.best_estimator_, model_name)\n",
        "\n",
        "            report_df = pd.DataFrame(report).transpose()\n",
        "            report_path = f\"{model_name}_classification_report.csv\"\n",
        "            report_df.to_csv(report_path, index=True)\n",
        "            mlflow.log_artifact(report_path)\n",
        "    \n",
        "    print(\"Se ha acabado el entrenamiento de los modelos correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "from funciones import argumentos, load_dataset, data_treatment, setup_ngrok, mlflow_tracking\n",
        "\n",
        "def main():\n",
        "    print(\"Ejecutamos el main\")\n",
        "    args_values = argumentos()\n",
        "    df = load_dataset()\n",
        "    X_train, X_test, y_train, y_test = data_treatment(df)\n",
        "    public_url = setup_ngrok(6000)\n",
        "    mlflow_tracking(args_values.nombre_job, X_train, X_test, y_train, y_test, 6000)\n",
        "    input(\"Presiona Enter para finalizar la sesión de ngrok...\")\n",
        "    ngrok.disconnect(public_url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ejecutamos el main\n",
            "ngrok URL: NgrokTunnel: \"https://a4c7-46-37-82-200.ngrok-free.app\" -> \"http://localhost:6000\"\n",
            "<Popen: returncode: None args: ['mlflow', 'ui', '--port', '6000']>\n",
            "[2024-07-12 19:45:54 +0200] [3402] [INFO] Starting gunicorn 22.0.0\n",
            "[2024-07-12 19:45:54 +0200] [3402] [INFO] Listening at: http://127.0.0.1:6000 (3402)\n",
            "[2024-07-12 19:45:54 +0200] [3402] [INFO] Using worker: sync\n",
            "[2024-07-12 19:45:54 +0200] [3403] [INFO] Booting worker with pid: 3403\n",
            "[2024-07-12 19:45:54 +0200] [3405] [INFO] Booting worker with pid: 3405\n",
            "[2024-07-12 19:45:54 +0200] [3406] [INFO] Booting worker with pid: 3406\n",
            "[2024-07-12 19:45:54 +0200] [3407] [INFO] Booting worker with pid: 3407\n",
            "/Users/sdiamar/opt/anaconda3/envs/Ower/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "Se ha acabado el entrenamiento de los modelos correctamente\n",
            "Presiona Enter para finalizar la sesión de ngrok...^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/sdiamar/Library/CloudStorage/OneDrive-Personal/Documentos/SARA/BOOTCAMP_KEEPCODING/BOOTCAMP_BD/Github_Noviembre/despliegue-algoritmos-main/main.py\", line 14, in <module>\n",
            "[2024-07-12 19:49:03 +0200] [3402] [INFO] Handling signal: int\n",
            "    main()\n",
            "  File \"/Users/sdiamar/Library/CloudStorage/OneDrive-Personal/Documentos/SARA/BOOTCAMP_KEEPCODING/BOOTCAMP_BD/Github_Noviembre/despliegue-algoritmos-main/main.py\", line 10, in main\n",
            "    input(\"Presiona Enter para finalizar la sesión de ngrok...\")\n",
            "KeyboardInterrupt\n",
            "[2024-07-12 19:49:03 +0200] [3405] [INFO] Worker exiting (pid: 3405)\n",
            "[2024-07-12 19:49:03 +0200] [3406] [INFO] Worker exiting (pid: 3406)\n",
            "[2024-07-12 19:49:03 +0200] [3403] [INFO] Worker exiting (pid: 3403)\n",
            "[2024-07-12 19:49:03 +0200] [3407] [INFO] Worker exiting (pid: 3407)\n"
          ]
        }
      ],
      "source": [
        "!python main.py --nombre_job \"ComparacionModelos\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adjunto capturas de pantalla de MLFlow para verificar de nuevo que todo ha ido bien:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Modelos inicio colab](./images_mlflow/Modelos_inicio_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Overview_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Metrics_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Artifacts_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Report_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Overview_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Metrics_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Artifacts_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Report_main.png)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 3: Práctica Flask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "He hecho esta parte de la práctica con Flask y lo he adjuntado al repositorio en un archivo llamado app.py y las carpetas pertinentes para su correcta ejecución y salida por ngrok. Debido a falta de tiempo no he podido desplegarlo en Google Cloud Run como paso opcional.\n",
        "He desarrollado una web que contiene una página de inicio, dos páginas donde se ejecutan algoritmos de HF como análisis de sentimiento y generación de texto, y por último, he añadido dos módulos más para mostrar los resultados de los modelos ejecutados en el ejercicio 1: LR y KNN.\n",
        "\n",
        "En este ejercicio, he obtenido el token de ngrok a través de un archivo .env con mi clave y cargándolo en el archivo con load_dotenv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
