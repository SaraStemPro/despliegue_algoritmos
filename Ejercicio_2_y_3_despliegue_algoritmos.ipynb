{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 2: Generar .py de funciones y main con al menos dos argumentos de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting funciones.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile funciones.py\n",
        "import argparse\n",
        "import subprocess\n",
        "import time\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.datasets import load_wine\n",
        "from pyngrok import ngrok\n",
        "\n",
        "def argumentos():\n",
        "    parser = argparse.ArgumentParser(description='__main__ de la aplicaci贸n con argumentos de entrada.')\n",
        "    parser.add_argument('--nombre_job', type=str, help='Nombre del experimento en MLflow.')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def load_dataset():\n",
        "    wine = load_wine()\n",
        "    df = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n",
        "    df['target'] = wine['target']\n",
        "    return df\n",
        "\n",
        "def data_treatment(df):\n",
        "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    test_target = test['target']\n",
        "    test[['target']].to_csv('test-target.csv', index=False)\n",
        "    del test['target']\n",
        "    test.to_csv('test.csv', index=False)\n",
        "\n",
        "    features = [x for x in list(train.columns) if x != 'target']\n",
        "    x_raw = train[features]\n",
        "    y_raw = train['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x_raw, y_raw,\n",
        "                                                        test_size=0.20,\n",
        "                                                        random_state=123,\n",
        "                                                        stratify=y_raw)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def setup_ngrok(port=6000):\n",
        "    ngrok.set_auth_token('token_aqui') # indicar token\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(\"ngrok URL:\", public_url)\n",
        "    return public_url\n",
        "\n",
        "def mlflow_tracking(nombre_job, X_train, X_test, y_train, y_test, port=6000):\n",
        "    mlflow_ui_process = subprocess.Popen(['mlflow', 'ui', '--port', str(port)])\n",
        "    print(mlflow_ui_process)\n",
        "    time.sleep(5)\n",
        "    mlflow.set_experiment(nombre_job)\n",
        "\n",
        "    models_params = {\n",
        "        'LogisticRegression': (LogisticRegression(max_iter=1000), {\n",
        "            \"model__C\": [0.1, 1, 10],\n",
        "            \"model__solver\": [\"liblinear\", \"lbfgs\"]\n",
        "        }),\n",
        "        'KNeighborsClassifier': (KNeighborsClassifier(), {\n",
        "            \"model__n_neighbors\": [3, 5, 7],\n",
        "            \"model__weights\": [\"uniform\", \"distance\"]\n",
        "        })\n",
        "    }\n",
        "\n",
        "    for model_name, (model, params) in models_params.items():\n",
        "        with mlflow.start_run(run_name=model_name) as run:\n",
        "            preprocessor = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "            clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                  ('model', model)])\n",
        "            \n",
        "            grid_search = GridSearchCV(clf, params, cv=5, scoring='accuracy')\n",
        "            grid_search.fit(X_train, y_train)\n",
        "\n",
        "            best_params = grid_search.best_params_\n",
        "            accuracy_train = grid_search.score(X_train, y_train)\n",
        "            accuracy_test = grid_search.score(X_test, y_test)\n",
        "            y_pred = grid_search.predict(X_test)\n",
        "            report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "            mlflow.log_params(best_params)\n",
        "            mlflow.log_metric('accuracy_train', accuracy_train)\n",
        "            mlflow.log_metric('accuracy_test', accuracy_test)\n",
        "            mlflow.sklearn.log_model(grid_search.best_estimator_, model_name)\n",
        "\n",
        "            report_df = pd.DataFrame(report).transpose()\n",
        "            report_path = f\"{model_name}_classification_report.csv\"\n",
        "            report_df.to_csv(report_path, index=True)\n",
        "            mlflow.log_artifact(report_path)\n",
        "    \n",
        "    print(\"Se ha acabado el entrenamiento de los modelos correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "from funciones import argumentos, load_dataset, data_treatment, setup_ngrok, mlflow_tracking\n",
        "\n",
        "def main():\n",
        "    print(\"Ejecutamos el main\")\n",
        "    args_values = argumentos()\n",
        "    df = load_dataset()\n",
        "    X_train, X_test, y_train, y_test = data_treatment(df)\n",
        "    public_url = setup_ngrok(6000)\n",
        "    mlflow_tracking(args_values.nombre_job, X_train, X_test, y_train, y_test, 6000)\n",
        "    input(\"Presiona Enter para finalizar la sesi贸n de ngrok...\")\n",
        "    ngrok.disconnect(public_url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ejecutamos el main\n",
            "ngrok URL: NgrokTunnel: \"https://a4c7-46-37-82-200.ngrok-free.app\" -> \"http://localhost:6000\"\n",
            "<Popen: returncode: None args: ['mlflow', 'ui', '--port', '6000']>\n",
            "[2024-07-12 19:45:54 +0200] [3402] [INFO] Starting gunicorn 22.0.0\n",
            "[2024-07-12 19:45:54 +0200] [3402] [INFO] Listening at: http://127.0.0.1:6000 (3402)\n",
            "[2024-07-12 19:45:54 +0200] [3402] [INFO] Using worker: sync\n",
            "[2024-07-12 19:45:54 +0200] [3403] [INFO] Booting worker with pid: 3403\n",
            "[2024-07-12 19:45:54 +0200] [3405] [INFO] Booting worker with pid: 3405\n",
            "[2024-07-12 19:45:54 +0200] [3406] [INFO] Booting worker with pid: 3406\n",
            "[2024-07-12 19:45:54 +0200] [3407] [INFO] Booting worker with pid: 3407\n",
            "/Users/sdiamar/opt/anaconda3/envs/Ower/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "Se ha acabado el entrenamiento de los modelos correctamente\n",
            "Presiona Enter para finalizar la sesi贸n de ngrok...^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/sdiamar/Library/CloudStorage/OneDrive-Personal/Documentos/SARA/BOOTCAMP_KEEPCODING/BOOTCAMP_BD/Github_Noviembre/despliegue-algoritmos-main/main.py\", line 14, in <module>\n",
            "[2024-07-12 19:49:03 +0200] [3402] [INFO] Handling signal: int\n",
            "    main()\n",
            "  File \"/Users/sdiamar/Library/CloudStorage/OneDrive-Personal/Documentos/SARA/BOOTCAMP_KEEPCODING/BOOTCAMP_BD/Github_Noviembre/despliegue-algoritmos-main/main.py\", line 10, in main\n",
            "    input(\"Presiona Enter para finalizar la sesi贸n de ngrok...\")\n",
            "KeyboardInterrupt\n",
            "[2024-07-12 19:49:03 +0200] [3405] [INFO] Worker exiting (pid: 3405)\n",
            "[2024-07-12 19:49:03 +0200] [3406] [INFO] Worker exiting (pid: 3406)\n",
            "[2024-07-12 19:49:03 +0200] [3403] [INFO] Worker exiting (pid: 3403)\n",
            "[2024-07-12 19:49:03 +0200] [3407] [INFO] Worker exiting (pid: 3407)\n"
          ]
        }
      ],
      "source": [
        "!python main.py --nombre_job \"ComparacionModelos\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adjunto capturas de pantalla de MLFlow para verificar de nuevo que todo ha ido bien:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Modelos inicio colab](./images_mlflow/Modelos_inicio_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Overview_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Metrics_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Artifacts_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/KNN_Report_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Overview_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Metrics_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Artifacts_main.png).\n",
        "![Modelos inicio colab](./images_mlflow/LR_Report_main.png)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 3: Pr谩ctica Flask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "He hecho esta parte de la pr谩ctica con Flask y lo he adjuntado al repositorio en un archivo llamado app.py y las carpetas pertinentes para su correcta ejecuci贸n y salida por ngrok. Debido a falta de tiempo no he podido desplegarlo en Google Cloud Run como paso opcional.\n",
        "He desarrollado una web que contiene una p谩gina de inicio, dos p谩ginas donde se ejecutan algoritmos de HF como an谩lisis de sentimiento y generaci贸n de texto, y por 煤ltimo, he a帽adido dos m贸dulos m谩s para mostrar los resultados de los modelos ejecutados en el ejercicio 1: LR y KNN.\n",
        "\n",
        "En este ejercicio, he obtenido el token de ngrok a trav茅s de un archivo .env con mi clave y carg谩ndolo en el archivo con load_dotenv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
